# Kalp Krizi Risk Tahmin Modeli

Bu proje, kalp krizi riskini tahmin etmek iÃ§in makine Ã¶ÄŸrenmesi modeli geliÅŸtirmeyi amaÃ§lamaktadÄ±r. **Outlier'lÄ± ve outliersÄ±z veriler iÃ§in karÅŸÄ±laÅŸtÄ±rmalÄ± analiz** yaparak en optimal modeli belirler.

## Proje YapÄ±sÄ±

```
cardiyovask/
â”œâ”€â”€ data/                   # Veri dosyalarÄ±
â”‚   â””â”€â”€ cardiokaggle.csv   # Ham veri
â”œâ”€â”€ src/                   # Kaynak kodlar
â”‚   â”œâ”€â”€ data/             # Veri iÅŸleme modÃ¼lleri
â”‚   â”‚   â”œâ”€â”€ cardiokaggle.csv
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â””â”€â”€ preprocessor.py
â”‚   â”œâ”€â”€ analysis/         # Veri analizi modÃ¼lleri
â”‚   â”‚   â””â”€â”€ data_analysis.py
â”‚   â”œâ”€â”€ utils/            # YardÄ±mcÄ± fonksiyonlar
â”‚   â”‚   â””â”€â”€ data_loader.py
â”‚   â”œâ”€â”€ main.py           # Ana Ã§alÄ±ÅŸtÄ±rma dosyasÄ±
â”‚   â”œâ”€â”€ clean_data.py     # Veri temizleme scripti
â”‚   â”œâ”€â”€ clean_bp_outliers.py
â”‚   â”œâ”€â”€ test_analysis.py
â”‚   â””â”€â”€ test_cleaned_data.py
â”œâ”€â”€ requirements.txt      # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md            # Proje dokÃ¼mantasyonu
```

## Kurulum

```bash
pip install -r requirements.txt
```

## KullanÄ±m

### KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz Pipeline

Outlier'lÄ± ve outliersÄ±z veriler iÃ§in karÅŸÄ±laÅŸtÄ±rmalÄ± analiz Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
cd src
python main.py
```

### AyrÄ± ModÃ¼ller

**KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz iÃ§in:**
```bash
python src/analysis/data_analysis.py
```

**Veri Temizleme iÃ§in:**
```bash
python src/clean_data.py
```

**Test Analizi iÃ§in:**
```bash
python src/test_analysis.py
```

## Ã–zellikler

### Veri Ä°ÅŸleme
- âœ… YaÅŸ kolonunu gÃ¼n formatÄ±ndan yÄ±l formatÄ±na Ã§evirme
- âœ… Eksik deÄŸer kontrolÃ¼ ve temizleme
- âœ… Outlier sayÄ±sÄ± hesaplama ve raporlama
- âœ… **Outlier temizleme seÃ§eneÄŸi** (IQR metoduna gÃ¶re)
- âœ… Kategorik deÄŸiÅŸkenlerin encode edilmesi (gender, smoke, alco, active)
- âœ… SÃ¼rekli deÄŸiÅŸkenlerin Ã¶lÃ§eklenmesi (StandardScaler)
- âœ… EÄŸitim/test setlerine %80-%20 ayrÄ±mÄ±

### Modelleme
- âœ… Random Forest Classifier
- âœ… Gradient Boosting Classifier
- âœ… Logistic Regression
- âœ… Support Vector Machine (SVM)
- âœ… **XGBoost Classifier** (Yeni!)

### DeÄŸerlendirme Metrikleri
- âœ… Accuracy, Precision, Recall, F1-Score
- âœ… ROC AUC Score
- âœ… Confusion Matrix
- âœ… Feature Importance (Random Forest ve XGBoost)

### KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz
- âœ… **Outlier'lÄ± vs OutliersÄ±z veri karÅŸÄ±laÅŸtÄ±rmasÄ±**
- âœ… Her iki veri seti iÃ§in ayrÄ± model eÄŸitimi
- âœ… Performans metriklerinin karÅŸÄ±laÅŸtÄ±rmalÄ± analizi
- âœ… En iyi model seÃ§imi (her veri seti iÃ§in)
- âœ… Outlier temizlemenin etkisinin Ã¶lÃ§Ã¼lmesi

### GÃ¶rselleÅŸtirme
- âœ… Confusion Matrix grafikleri (her veri seti iÃ§in)
- âœ… ROC eÄŸrileri (her veri seti iÃ§in)
- âœ… Model performans karÅŸÄ±laÅŸtÄ±rmasÄ± (her veri seti iÃ§in)
- âœ… Feature importance grafiÄŸi (Random Forest ve XGBoost)
- âœ… **KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz grafikleri** (Yeni!)

## Ã‡Ä±ktÄ±lar

Pipeline Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda aÅŸaÄŸÄ±daki Ã§Ä±ktÄ±lar oluÅŸturulur:

### 1. Konsol Ã‡Ä±ktÄ±larÄ±
- Veri iÅŸleme adÄ±mlarÄ± (her iki veri seti iÃ§in)
- Outlier sayÄ±larÄ± (Ã§Ä±karÄ±lmadan Ã¶nce ve sonra)
- Model performans metrikleri (her iki veri seti iÃ§in)
- X_train.shape, X_test.shape (her iki veri seti iÃ§in)
- **KarÅŸÄ±laÅŸtÄ±rmalÄ± sonuÃ§lar tablosu**
- **En iyi model karÅŸÄ±laÅŸtÄ±rmasÄ±**
- **Outlier temizlemenin performans etkisi**

### 2. Grafik DosyalarÄ±
- `confusion_matrices.png` - TÃ¼m modellerin confusion matrix'leri (her veri seti iÃ§in)
- `roc_curves.png` - ROC eÄŸrileri (her veri seti iÃ§in)
- `metrics_comparison.png` - Model performans karÅŸÄ±laÅŸtÄ±rmasÄ± (her veri seti iÃ§in)
- `rf_feature_importance.png` - Random Forest feature importance (her veri seti iÃ§in)
- `xgb_feature_importance.png` - XGBoost feature importance (her veri seti iÃ§in)
- `comparative_analysis.png` - **KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz grafikleri** (Yeni!)

## Veri Seti

KullanÄ±lan veri seti aÅŸaÄŸÄ±daki kolonlarÄ± iÃ§erir:
- `id`: Hasta ID
- `age`: YaÅŸ (gÃ¼n cinsinden)
- `gender`: Cinsiyet
- `height`: Boy
- `weight`: Kilo
- `ap_hi`: Sistolik tansiyon
- `ap_lo`: Diastolik tansiyon
- `cholesterol`: Kolesterol seviyesi
- `gluc`: Glikoz seviyesi
- `smoke`: Sigara kullanÄ±mÄ±
- `alco`: Alkol kullanÄ±mÄ±
- `active`: Fiziksel aktivite
- `cardio`: KardiyovaskÃ¼ler hastalÄ±k (hedef deÄŸiÅŸken)

## KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz Ã–zellikleri

### Outlier Temizleme
- **IQR Metodu**: Q1 - 1.5*IQR ve Q3 + 1.5*IQR aralÄ±ÄŸÄ± dÄ±ÅŸÄ±ndaki deÄŸerler outlier olarak kabul edilir
- **Temizlenen Kolonlar**: height, weight, ap_hi, ap_lo, cholesterol, gluc
- **KarÅŸÄ±laÅŸtÄ±rma**: Outlier'lÄ± ve outliersÄ±z veriler iÃ§in ayrÄ± model eÄŸitimi

### Model KarÅŸÄ±laÅŸtÄ±rmasÄ±
- Her veri seti iÃ§in 5 farklÄ± model eÄŸitilir
- F1-Score'a gÃ¶re en iyi model seÃ§ilir
- Outlier temizlemenin performans etkisi Ã¶lÃ§Ã¼lÃ¼r

### GÃ¶rselleÅŸtirme
- KarÅŸÄ±laÅŸtÄ±rmalÄ± bar grafikleri
- Her metrik iÃ§in ayrÄ± karÅŸÄ±laÅŸtÄ±rma
- Outlier'lÄ± vs outliersÄ±z performans farkÄ±

## Gereksinimler

- Python 3.8+
- pandas >= 1.5.0
- numpy >= 1.21.0
- scikit-learn >= 1.1.0
- matplotlib >= 3.5.0
- seaborn >= 0.11.0
- **xgboost >= 1.6.0** (Yeni!) 
#############################################################
================================================================================
KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - KARÅILAÅTIRMALI ANALÄ°Z PIPELINE
================================================================================
Veri dosyasÄ±: /Users/aybukealtuntas/Desktop/cardiovasktrain/cardiyovask/src/data/cardiokaggle.csv

==================================================
1. VERÄ° Ä°ÅLEME VE FEATURE ENGINEERING
==================================================

--- Outlier'lÄ± Verilerle Ä°ÅŸleme ---
=== KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - OUTLIER'LAR Ä°LE VERÄ° Ä°ÅLEME ===

Veri baÅŸarÄ±yla yÃ¼klendi! Boyut: (70000, 13)
Kolonlar: ['id', 'age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']
YaÅŸ dÃ¶nÃ¼ÅŸÃ¼mÃ¼ tamamlandÄ±. Ã–rnek deÄŸerler:
GÃ¼n: [18393, 20228, 18857] -> YÄ±l: [50, 55, 51]

=== EKSÄ°K DEÄER ANALÄ°ZÄ° ===
Toplam eksik deÄŸer: 0
Eksik deÄŸer bulunmamaktadÄ±r.
Eksik deÄŸerler silindi. Yeni boyut: (70000, 14)

=== OUTLIER ANALÄ°ZÄ° ===
height: 519 outlier (0.74%)
weight: 1819 outlier (2.60%)
ap_hi: 1435 outlier (2.05%)
ap_lo: 4632 outlier (6.62%)
cholesterol: 0 outlier (0.00%)
gluc: 10521 outlier (15.03%)

Toplam outlier sayÄ±sÄ±: 18926

=== KATEGORÄ°K DEÄÄ°ÅKEN ENCODING ===
gender: 2 benzersiz deÄŸer -> [1, 2] -> [0, 1]
smoke: 2 benzersiz deÄŸer -> [0, 1] -> [0, 1]
alco: 2 benzersiz deÄŸer -> [0, 1] -> [0, 1]
active: 2 benzersiz deÄŸer -> [0, 1] -> [0, 1]

=== SÃœREKLÄ° DEÄÄ°ÅKEN Ã–LÃ‡EKLEME ===
Ã–lÃ§eklenen kolonlar: ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc']
StandardScaler uygulandÄ± (ortalama=0, standart sapma=1)

Feature matrix boyutu: (70000, 11)
Hedef deÄŸiÅŸken boyutu: (70000,)
Feature kolonlarÄ±: ['gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'age_years']

=== VERÄ° AYRIMI ===
EÄŸitim seti: (56000, 11)
Test seti: (14000, 11)
EÄŸitim hedef: (56000,)
Test hedef: (14000,)

=== OUTLIER'LAR Ä°LE VERÄ° Ä°ÅLEME TAMAMLANDI ===

--- Outlier'lar Ã‡Ä±karÄ±larak Ä°ÅŸleme ---
=== KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - OUTLIER'LAR Ã‡IKARILARAK VERÄ° Ä°ÅLEME ===

Veri baÅŸarÄ±yla yÃ¼klendi! Boyut: (70000, 13)
Kolonlar: ['id', 'age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']
YaÅŸ dÃ¶nÃ¼ÅŸÃ¼mÃ¼ tamamlandÄ±. Ã–rnek deÄŸerler:
GÃ¼n: [18393, 20228, 18857] -> YÄ±l: [50, 55, 51]

=== EKSÄ°K DEÄER ANALÄ°ZÄ° ===
Toplam eksik deÄŸer: 0
Eksik deÄŸer bulunmamaktadÄ±r.
Eksik deÄŸerler silindi. Yeni boyut: (70000, 14)

=== OUTLIER ANALÄ°ZÄ° ===
height: 519 outlier (0.74%)
weight: 1819 outlier (2.60%)
ap_hi: 1435 outlier (2.05%)
ap_lo: 4632 outlier (6.62%)
cholesterol: 0 outlier (0.00%)
gluc: 10521 outlier (15.03%)

Toplam outlier sayÄ±sÄ±: 18926

=== OUTLIER TEMÄ°ZLEME ===
height: 519 outlier Ã§Ä±karÄ±ldÄ±
weight: 1819 outlier Ã§Ä±karÄ±ldÄ±
ap_hi: 1435 outlier Ã§Ä±karÄ±ldÄ±
ap_lo: 4632 outlier Ã§Ä±karÄ±ldÄ±
cholesterol: 0 outlier Ã§Ä±karÄ±ldÄ±
gluc: 10521 outlier Ã§Ä±karÄ±ldÄ±
Toplam 18926 outlier Ã§Ä±karÄ±ldÄ±
Orijinal boyut: (70000, 14) -> TemizlenmiÅŸ boyut: (53408, 14)

=== KATEGORÄ°K DEÄÄ°ÅKEN ENCODING ===
gender: 2 benzersiz deÄŸer -> [1, 2] -> [0, 1]
smoke: 2 benzersiz deÄŸer -> [0, 1] -> [0, 1]
alco: 2 benzersiz deÄŸer -> [0, 1] -> [0, 1]
active: 2 benzersiz deÄŸer -> [0, 1] -> [0, 1]

=== SÃœREKLÄ° DEÄÄ°ÅKEN Ã–LÃ‡EKLEME ===
Ã–lÃ§eklenen kolonlar: ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc']
StandardScaler uygulandÄ± (ortalama=0, standart sapma=1)

Feature matrix boyutu: (53408, 11)
Hedef deÄŸiÅŸken boyutu: (53408,)
Feature kolonlarÄ±: ['gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'age_years']

=== VERÄ° AYRIMI ===
EÄŸitim seti: (42726, 11)
Test seti: (10682, 11)
EÄŸitim hedef: (42726,)
Test hedef: (10682,)

=== OUTLIER'LAR Ã‡IKARILARAK VERÄ° Ä°ÅLEME TAMAMLANDI ===

==================================================
2. KARÅILAÅTIRMALI MODEL EÄÄ°TÄ°MÄ° VE DEÄERLENDÄ°RME
==================================================
================================================================================
KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - KARÅILAÅTIRMALI ANALÄ°Z
================================================================================

========================================
1. OUTLIER'LAR Ä°LE ANALÄ°Z
========================================
=== KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - TAM ANALÄ°Z (WITH_OUTLIERS) ===

=== MODEL EÄÄ°TÄ°MÄ° ===

Random Forest eÄŸitiliyor...
Random Forest eÄŸitimi tamamlandÄ±.

Gradient Boosting eÄŸitiliyor...
Gradient Boosting eÄŸitimi tamamlandÄ±.

Logistic Regression eÄŸitiliyor...
Logistic Regression eÄŸitimi tamamlandÄ±.

SVM eÄŸitiliyor...
SVM eÄŸitimi tamamlandÄ±.

XGBoost eÄŸitiliyor...
XGBoost eÄŸitimi tamamlandÄ±.

TÃ¼m modeller eÄŸitildi!

=== MODEL DEÄERLENDÄ°RMESÄ° ===

Random Forest deÄŸerlendiriliyor...
Accuracy: 0.7077
Precision: 0.7093
Recall: 0.7033
F1-Score: 0.7063
ROC AUC: 0.7635

Gradient Boosting deÄŸerlendiriliyor...
Accuracy: 0.7336
Precision: 0.7507
Recall: 0.6990
F1-Score: 0.7239
ROC AUC: 0.7997

Logistic Regression deÄŸerlendiriliyor...
Accuracy: 0.7141
Precision: 0.7318
Recall: 0.6754
F1-Score: 0.7024
ROC AUC: 0.7783

SVM deÄŸerlendiriliyor...
Accuracy: 0.7294
Precision: 0.7440
Recall: 0.6990
F1-Score: 0.7208
ROC AUC: 0.7859

XGBoost deÄŸerlendiriliyor...
Accuracy: 0.7339
Precision: 0.7530
Recall: 0.6958
F1-Score: 0.7233
ROC AUC: 0.8000

=== EN Ä°YÄ° MODEL SEÃ‡Ä°MÄ° ===
Random Forest: F1-Score = 0.7063
Gradient Boosting: F1-Score = 0.7239
Logistic Regression: F1-Score = 0.7024
SVM: F1-Score = 0.7208
XGBoost: F1-Score = 0.7233

En iyi model: Gradient Boosting (F1-Score: 0.7239)

=== Gradient Boosting - DETAYLI SINIFLANDIRMA RAPORU ===
                     precision    recall  f1-score   support

KardiyovaskÃ¼ler Yok       0.72      0.77      0.74      7004
KardiyovaskÃ¼ler Var       0.75      0.70      0.72      6996

           accuracy                           0.73     14000
          macro avg       0.73      0.73      0.73     14000
       weighted avg       0.73      0.73      0.73     14000


GÃ¶rselleÅŸtirmeler oluÅŸturuluyor...
2025-08-11 21:20:37.709 python[80049:13502621] +[IMKClient subclass]: chose IMKClient_Legacy
2025-08-11 21:20:37.709 python[80049:13502621] +[IMKInputSession subclass]: chose IMKInputSession_Legacy

=== ANALÄ°Z TAMAMLANDI (WITH_OUTLIERS) ===
En iyi model: Gradient Boosting
En iyi F1-Score: 0.7239

========================================
2. OUTLIER'LAR Ã‡IKARILARAK ANALÄ°Z
========================================
=== KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - TAM ANALÄ°Z (WITHOUT_OUTLIERS) ===

=== MODEL EÄÄ°TÄ°MÄ° ===

Random Forest eÄŸitiliyor...
Random Forest eÄŸitimi tamamlandÄ±.

Gradient Boosting eÄŸitiliyor...
Gradient Boosting eÄŸitimi tamamlandÄ±.

Logistic Regression eÄŸitiliyor...
Logistic Regression eÄŸitimi tamamlandÄ±.

SVM eÄŸitiliyor...
SVM eÄŸitimi tamamlandÄ±.

XGBoost eÄŸitiliyor...
XGBoost eÄŸitimi tamamlandÄ±.

TÃ¼m modeller eÄŸitildi!

=== MODEL DEÄERLENDÄ°RMESÄ° ===

Random Forest deÄŸerlendiriliyor...
Accuracy: 0.7070
Precision: 0.7006
Recall: 0.6714
F1-Score: 0.6857
ROC AUC: 0.7634

Gradient Boosting deÄŸerlendiriliyor...
Accuracy: 0.7395
Precision: 0.7570
Recall: 0.6667
F1-Score: 0.7090
ROC AUC: 0.8056

Logistic Regression deÄŸerlendiriliyor...
Accuracy: 0.7344
Precision: 0.7653
Recall: 0.6376
F1-Score: 0.6956
ROC AUC: 0.7984

SVM deÄŸerlendiriliyor...
Accuracy: 0.7368
Precision: 0.7798
Recall: 0.6232
F1-Score: 0.6928
ROC AUC: 0.7870

XGBoost deÄŸerlendiriliyor...
Accuracy: 0.7416
Precision: 0.7658
Recall: 0.6586
F1-Score: 0.7082
ROC AUC: 0.8046

=== EN Ä°YÄ° MODEL SEÃ‡Ä°MÄ° ===
Random Forest: F1-Score = 0.6857
Gradient Boosting: F1-Score = 0.7090
Logistic Regression: F1-Score = 0.6956
SVM: F1-Score = 0.6928
XGBoost: F1-Score = 0.7082

En iyi model: Gradient Boosting (F1-Score: 0.7090)

=== Gradient Boosting - DETAYLI SINIFLANDIRMA RAPORU ===
                     precision    recall  f1-score   support

KardiyovaskÃ¼ler Yok       0.73      0.81      0.76      5597
KardiyovaskÃ¼ler Var       0.76      0.67      0.71      5085

           accuracy                           0.74     10682
          macro avg       0.74      0.74      0.74     10682
       weighted avg       0.74      0.74      0.74     10682


GÃ¶rselleÅŸtirmeler oluÅŸturuluyor...
2025-08-11 21:52:41.536 python[80049:13502621] _TIPropertyValueIsValid called with 16 on nil context!
2025-08-11 21:52:41.536 python[80049:13502621] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.
2025-08-11 21:52:41.536 python[80049:13502621] Text input context does not respond to _valueForTIProperty:
2025-08-11 21:54:29.329 python[80049:13502621] _TIPropertyValueIsValid called with 16 on nil context!
2025-08-11 21:54:29.329 python[80049:13502621] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.
2025-08-11 21:54:29.329 python[80049:13502621] Text input context does not respond to _valueForTIProperty:

=== ANALÄ°Z TAMAMLANDI (WITHOUT_OUTLIERS) ===
En iyi model: Gradient Boosting
En iyi F1-Score: 0.7090

========================================
3. KARÅILAÅTIRMALI SONUÃ‡LAR
========================================

=== KARÅILAÅTIRMALI SONUÃ‡LAR TABLOSU ===
              Model  Accuracy  Precision   Recall  F1-Score  ROC AUC        Data_Type
      Random Forest  0.707714   0.709343 0.703259  0.706288 0.763495    With Outliers
  Gradient Boosting  0.733571   0.750691 0.698971  0.723908 0.799737    With Outliers
Logistic Regression  0.714071   0.731764 0.675386  0.702446 0.778264    With Outliers
                SVM  0.729357   0.743953 0.698971  0.720761 0.785948    With Outliers
            XGBoost  0.733929   0.752978 0.695826  0.723275 0.799985    With Outliers
      Random Forest  0.706984   0.700595 0.671386  0.685680 0.763354 Without Outliers
  Gradient Boosting  0.739468   0.757034 0.666667  0.708983 0.805611 Without Outliers
Logistic Regression  0.734413   0.765345 0.637561  0.695634 0.798412 Without Outliers
                SVM  0.736847   0.779774 0.623206  0.692753 0.787034 Without Outliers
            XGBoost  0.741621   0.765836 0.658604  0.708184 0.804620 Without Outliers

=== EN Ä°YÄ° MODEL KARÅILAÅTIRMASI ===
Outlier'lÄ± veriler: Gradient Boosting (F1: 0.7239)
Outlier'lar Ã§Ä±karÄ±lmÄ±ÅŸ: Gradient Boosting (F1: 0.7090)
Outlier temizleme ile F1-Score azalÄ±ÅŸÄ±: -0.0149

================================================================================
FÄ°NAL KARÅILAÅTIRMALI SONUÃ‡LAR
================================================================================

OUTLIER'LAR Ä°LE:
X_train.shape: (56000, 11)
X_test.shape: (14000, 11)
En iyi model: Gradient Boosting
En iyi F1-Score: 0.7239

Outlier Analizi (Ã§Ä±karÄ±lmadan):
  height: 519 outlier
  weight: 1819 outlier
  ap_hi: 1435 outlier
  ap_lo: 4632 outlier
  cholesterol: 0 outlier
  gluc: 10521 outlier

OUTLIER'LAR Ã‡IKARILARAK:
X_train.shape: (42726, 11)
X_test.shape: (10682, 11)
En iyi model: Gradient Boosting
En iyi F1-Score: 0.7090

Outlier Analizi (Ã§Ä±karÄ±ldÄ±ktan sonra):
  height: 519 outlier (Ã§Ä±karÄ±ldÄ±)
  weight: 1819 outlier (Ã§Ä±karÄ±ldÄ±)
  ap_hi: 1435 outlier (Ã§Ä±karÄ±ldÄ±)
  ap_lo: 4632 outlier (Ã§Ä±karÄ±ldÄ±)
  cholesterol: 0 outlier (Ã§Ä±karÄ±ldÄ±)
  gluc: 10521 outlier (Ã§Ä±karÄ±ldÄ±)

Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Outlier'lÄ±):
              Model  Accuracy  Precision   Recall  F1-Score  ROC AUC
      Random Forest  0.707714   0.709343 0.703259  0.706288 0.763495
  Gradient Boosting  0.733571   0.750691 0.698971  0.723908 0.799737
Logistic Regression  0.714071   0.731764 0.675386  0.702446 0.778264
                SVM  0.729357   0.743953 0.698971  0.720761 0.785948
            XGBoost  0.733929   0.752978 0.695826  0.723275 0.799985

Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Outlier'lar Ã§Ä±karÄ±lmÄ±ÅŸ):
              Model  Accuracy  Precision   Recall  F1-Score  ROC AUC
      Random Forest  0.706984   0.700595 0.671386  0.685680 0.763354
  Gradient Boosting  0.739468   0.757034 0.666667  0.708983 0.805611
Logistic Regression  0.734413   0.765345 0.637561  0.695634 0.798412
                SVM  0.736847   0.779774 0.623206  0.692753 0.787034
            XGBoost  0.741621   0.765836 0.658604  0.708184 0.804620

En Ã–nemli 10 Feature - Outlier'lÄ± Veriler (Random Forest):
  weight: 0.2308
  height: 0.2101
  ap_hi: 0.1931
  age_years: 0.1635
  ap_lo: 0.0912
  cholesterol: 0.0392
  gluc: 0.0195
  gender: 0.0185
  active: 0.0161
  smoke: 0.0097

En Ã–nemli 10 Feature - Outlier'lar Ã§Ä±karÄ±lmÄ±ÅŸ (Random Forest):
  weight: 0.2491
  height: 0.2220
  ap_hi: 0.1939
  age_years: 0.1714
  ap_lo: 0.0776
  cholesterol: 0.0367
  gender: 0.0175
  active: 0.0148
  smoke: 0.0093
  alco: 0.0078

================================================================================
KARÅILAÅTIRMALI ANALÄ°Z PIPELINE TAMAMLANDI!
================================================================================
Grafikler proje dizinine kaydedildi:
- confusion_matrices.png (her iki veri seti iÃ§in)
- roc_curves.png (her iki veri seti iÃ§in)
- metrics_comparison.png (her iki veri seti iÃ§in)
- rf_feature_importance.png (her iki veri seti iÃ§in)
- xgb_feature_importance.png (her iki veri seti iÃ§in)
- comparative_analysis.png (karÅŸÄ±laÅŸtÄ±rmalÄ± sonuÃ§lar)
"""
Kalp Krizi Risk Tahmin Modeli - Optimizasyon Ana Ã‡alÄ±ÅŸtÄ±rma DosyasÄ±
"""

import sys
from pathlib import Path

# Proje kÃ¶k dizinini Python path'ine ekle
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from data.advanced_feature_engineering import AdvancedFeatureEngineer
from analysis.hyperparameter_tuning import HyperparameterTuner
from analysis.ensemble_methods import EnsembleMethods
from utils.data_loader import DataLoader

def main():
    """Ana fonksiyon - TÃ¼m optimizasyon pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±r."""
    print("="*80)
    print("KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - TAM OPTÄ°MÄ°ZASYON PIPELINE")
    print("="*80)
    
    # 1. Veri dosyasÄ± yolu
    data_path = project_root / "data" / "cardiokaggle.csv"
    
    if not data_path.exists():
        print(f"HATA: Veri dosyasÄ± bulunamadÄ±: {data_path}")
        return
    
    # 2. GELÄ°ÅMÄ°Å FEATURE ENGINEERING
    print("\n" + "="*50)
    print("1. GELÄ°ÅMÄ°Å FEATURE ENGINEERING")
    print("="*50)
    
    advanced_fe = AdvancedFeatureEngineer()
    advanced_data = advanced_fe.advanced_pipeline(str(data_path))
    
    if advanced_data is None:
        print("GeliÅŸmiÅŸ feature engineering baÅŸarÄ±sÄ±z!")
        return
    
    print(f"Feature sayÄ±sÄ±: {advanced_data['X_train'].shape[1]}")
    
    # 3. HYPERPARAMETER TUNING
    print("\n" + "="*50)
    print("2. HYPERPARAMETER TUNING")
    print("="*50)
    
    tuner = HyperparameterTuner()
    best_models = tuner.tune_all_models(
        advanced_data['X_train'],
        advanced_data['y_train'],
        cv=5,
        n_jobs=-1
    )
    
    # Tune edilmiÅŸ modelleri test setinde deÄŸerlendir
    tuning_results = tuner.evaluate_tuned_models(
        advanced_data['X_test'],
        advanced_data['y_test']
    )
    
    # 4. ENSEMBLE METHODS
    print("\n" + "="*50)
    print("3. ENSEMBLE METHODS")
    print("="*50)
    
    ensemble = EnsembleMethods()
    ensemble_results = ensemble.run_ensemble_analysis(
        advanced_data['X_train'],
        advanced_data['X_test'],
        advanced_data['y_train'],
        advanced_data['y_test']
    )
    
    # 5. FÄ°NAL SONUÃ‡LAR
    print("\n" + "="*80)
    print("FÄ°NAL OPTÄ°MÄ°ZASYON SONUÃ‡LARI")
    print("="*80)
    
    best_tuning_model = max(tuning_results.keys(), key=lambda x: tuning_results[x]['accuracy'])
    best_tuning_accuracy = tuning_results[best_tuning_model]['accuracy']
    
    best_ensemble_model = ensemble_results['best_model_name']
    best_ensemble_accuracy = ensemble_results['best_accuracy']
    
    print(f"Hyperparameter Tuning (En iyi): {best_tuning_accuracy:.4f}")
    print(f"Ensemble Methods (En iyi): {best_ensemble_accuracy:.4f}")
    
    if best_ensemble_accuracy > best_tuning_accuracy:
        print(f"ğŸ† En iyi sonuÃ§: {best_ensemble_model} ({best_ensemble_accuracy:.4f})")
    else:
        print(f"ğŸ† En iyi sonuÃ§: {best_tuning_model} ({best_tuning_accuracy:.4f})")

if __name__ == "__main__":
    main()
"""
Kalp Krizi Risk Tahmin Modeli - Optimizasyon Ana Ã‡alÄ±ÅŸtÄ±rma DosyasÄ±
"""

import sys
from pathlib import Path

# Proje kÃ¶k dizinini Python path'ine ekle
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from data.advanced_feature_engineering import AdvancedFeatureEngineer
from analysis.hyperparameter_tuning import HyperparameterTuner
from analysis.ensemble_methods import EnsembleMethods
from utils.data_loader import DataLoader

def main():
    """Ana fonksiyon - TÃ¼m optimizasyon pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±r."""
    print("="*80)
    print("KALP KRÄ°ZÄ° RÄ°SK TAHMÄ°N MODELÄ° - TAM OPTÄ°MÄ°ZASYON PIPELINE")
    print("="*80)
    
    # 1. Veri dosyasÄ± yolu
    data_path = project_root / "data" / "cardiokaggle.csv"
    
    if not data_path.exists():
        print(f"HATA: Veri dosyasÄ± bulunamadÄ±: {data_path}")
        return
    
    # 2. GELÄ°ÅMÄ°Å FEATURE ENGINEERING
    print("\n" + "="*50)
    print("1. GELÄ°ÅMÄ°Å FEATURE ENGINEERING")
    print("="*50)
    
    advanced_fe = AdvancedFeatureEngineer()
    advanced_data = advanced_fe.advanced_pipeline(str(data_path))
    
    if advanced_data is None:
        print("GeliÅŸmiÅŸ feature engineering baÅŸarÄ±sÄ±z!")
        return
    
    print(f"Feature sayÄ±sÄ±: {advanced_data['X_train'].shape[1]}")
    
    # 3. HYPERPARAMETER TUNING
    print("\n" + "="*50)
    print("2. HYPERPARAMETER TUNING")
    print("="*50)
    
    tuner = HyperparameterTuner()
    best_models = tuner.tune_all_models(
        advanced_data['X_train'],
        advanced_data['y_train'],
        cv=5,
        n_jobs=-1
    )
    
    # Tune edilmiÅŸ modelleri test setinde deÄŸerlendir
    tuning_results = tuner.evaluate_tuned_models(
        advanced_data['X_test'],
        advanced_data['y_test']
    )
    
    # 4. ENSEMBLE METHODS
    print("\n" + "="*50)
    print("3. ENSEMBLE METHODS")
    print("="*50)
    
    ensemble = EnsembleMethods()
    ensemble_results = ensemble.run_ensemble_analysis(
        advanced_data['X_train'],
        advanced_data['X_test'],
        advanced_data['y_train'],
        advanced_data['y_test']
    )
    
    # 5. FÄ°NAL SONUÃ‡LAR
    print("\n" + "="*80)
    print("FÄ°NAL OPTÄ°MÄ°ZASYON SONUÃ‡LARI")
    print("="*80)
    
    best_tuning_model = max(tuning_results.keys(), key=lambda x: tuning_results[x]['accuracy'])
    best_tuning_accuracy = tuning_results[best_tuning_model]['accuracy']
    
    best_ensemble_model = ensemble_results['best_model_name']
    best_ensemble_accuracy = ensemble_results['best_accuracy']
    
    print(f"Hyperparameter Tuning (En iyi): {best_tuning_accuracy:.4f}")
    print(f"Ensemble Methods (En iyi): {best_ensemble_accuracy:.4f}")
    
    if best_ensemble_accuracy > best_tuning_accuracy:
        print(f"ğŸ† En iyi sonuÃ§: {best_ensemble_model} ({best_ensemble_accuracy:.4f})")
    else:
        print(f"ğŸ† En iyi sonuÃ§: {best_tuning_model} ({best_tuning_accuracy:.4f})")

if __name__ == "__main__":
    main()